{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ceb86029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from quasarpy.quasar import Quasar, DatasetConfig, KrigingConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80bf835",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "We will use the same data as the integration test:\n",
    "$$ y(t) = (2x_1 + x_2) \\cdot (1 + 0.5t) $$\n",
    "\n",
    "Where:\n",
    "- $t \\in [0, 2]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1a8ec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 5\n",
      "    x1   x2\n",
      "0  1.0  1.0\n",
      "1  2.0  2.0\n",
      "2  3.0  1.0\n",
      "3  4.0  2.0\n",
      "4  5.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# Define the functions from the integration test\n",
    "def y1_func(t, x1, x2):\n",
    "    return (2 * x1 + x2) * (1 + 0.5 * t)\n",
    "\n",
    "def y2_func(t, x1, x2):\n",
    "    return (3 * x1 - x2) * np.exp(-0.3 * t)\n",
    "\n",
    "# Time steps\n",
    "t_steps = np.linspace(0, 2, 21)\n",
    "\n",
    "def generate_data_from_func(X_df, func, noise_std=0.0):\n",
    "    y_data = {}\n",
    "    for i in range(len(X_df)):\n",
    "        row = X_df.iloc[i]\n",
    "        curve = func(t_steps, row['x1'], row['x2'])\n",
    "        if noise_std > 0:\n",
    "            # Add Gaussian noise\n",
    "            curve += np.random.normal(0, noise_std, size=curve.shape)\n",
    "        y_data[i] = curve\n",
    "    return pd.DataFrame(y_data).T\n",
    "\n",
    "# Training Data (Same as test_quasar_integration)\n",
    "X_train = pd.DataFrame({\n",
    "    'x1': [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "    'x2': [1.0, 2.0, 1.0, 2.0, 1.0]\n",
    "})\n",
    "Y_train_1 = generate_data_from_func(X_train, y1_func, noise_std=0.0)\n",
    "Y_train_2 = generate_data_from_func(X_train, y2_func, noise_std=0.0)\n",
    "\n",
    "print(f\"Training Samples: {len(X_train)}\")\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46678a3e",
   "metadata": {},
   "source": [
    "## 2. Train the Model\n",
    "\n",
    "We configure a dataset and train the Quasar model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40836513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quasar initialized successfully.\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Configure Datasets\n",
    "ds_config_1 = DatasetConfig(\n",
    "    name='Dataset1',\n",
    "    data=Y_train_1,\n",
    "    kriging_config=KrigingConfig(basis_function=2) # Linear basis\n",
    ")\n",
    "\n",
    "ds_config_2 = DatasetConfig(\n",
    "    name='Dataset2',\n",
    "    data=Y_train_2,\n",
    "    kriging_config=KrigingConfig(basis_function=2) # Linear basis\n",
    ")\n",
    "\n",
    "# Initialize Quasar\n",
    "# Ensure ODYSSEE_CAE_INSTALLDIR is set in your environment\n",
    "try:\n",
    "    q = Quasar()\n",
    "    print(\"Quasar initialized successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    print(\"Please set ODYSSEE_CAE_INSTALLDIR to run this demo.\")\n",
    "\n",
    "# Train\n",
    "if 'q' in locals():\n",
    "    q.train(X_train, [ds_config_1, ds_config_2])\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4360b40e",
   "metadata": {},
   "source": [
    "## 3. Validation\n",
    "\n",
    "We generate a new set of data to validate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dad4a007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              RMSE       MAE  Peak Error     SRMSE\n",
      "Dataset                                           \n",
      "Dataset1  1.605251  1.305253    1.468734  0.286478\n",
      "Dataset2  0.517200  0.417442    0.573368  0.147594\n"
     ]
    }
   ],
   "source": [
    "# Generate Validation Data (Intermediate points with Noise)\n",
    "# Increase number of samples for better visualization\n",
    "X_val = pd.DataFrame({\n",
    "    'x1': np.random.uniform(0, 5, 20),\n",
    "    'x2': np.random.uniform(0, 5, 20)\n",
    "})\n",
    "\n",
    "# Add noise to validation data to make plots interesting\n",
    "# Amplitude is roughly 3 to 30, so noise of 1.0 is visible but not overwhelming\n",
    "Y_val_1 = generate_data_from_func(X_val, y1_func, noise_std=1.5)\n",
    "Y_val_2 = generate_data_from_func(X_val, y2_func, noise_std=0.5) # Smaller noise for smaller amplitude signal\n",
    "\n",
    "ds_val_1 = DatasetConfig(\n",
    "    name='Dataset1',\n",
    "    data=Y_val_1\n",
    ")\n",
    "\n",
    "ds_val_2 = DatasetConfig(\n",
    "    name='Dataset2',\n",
    "    data=Y_val_2\n",
    ")\n",
    "\n",
    "# Run Validation\n",
    "val_result = q.validate(X_val, [ds_val_1, ds_val_2])\n",
    "\n",
    "# Show Metrics Summary\n",
    "print(val_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe501f8d",
   "metadata": {},
   "source": [
    "## 4. Interactive Dashboard\n",
    "\n",
    "Use the dashboard below to inspect the results. \n",
    "- **Parity Plot**: Click on any point to see the corresponding curve comparison.\n",
    "- **Curve Comparison**: Shows the Actual (Black) vs Predicted (Blue Dashed) curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c09316e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ceff88e777d427d9ceef8856fea9a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Dataset:', options=('Dataset1', 'Dataset2'), value='Dataset1'), HBox(chilâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_result.dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e8c68",
   "metadata": {},
   "source": [
    "## 5. Export Report\n",
    "\n",
    "Save the validation results to an HTML file for sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd03623",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_result.save_html('validation_report.html')\n",
    "print('Report saved to validation_report.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
